myTesting <- testing[testCols]
dim(myTesting)
nzv <- nearZeroVar(pmlTraining, saveMetrics=TRUE)
myTraining <- pmlTraining[,nzv$nzv==FALSE]
myTesting <- pmlTesting[,nzv$nzv==FALSE]
pca3 = MFA(myTraining, group=c(3,35,29,35,27,1),type=c(rep("s",1),rep("s",1),rep("s",1),rep("s",1),rep("s",1),rep("n",1)), ncp=5,name.group=c("timestamp","belt","arm","dumbell", "foream","classe"),num.group.sup = c(1,5))
plot(pca3,choix="ind",partial="3")
pca3 = MFA(myTraining, group=c(13,13,13,13,1),type=c(rep("s",1),rep("s",1),rep("s",1),rep("s",1),rep("n",1)), ncp=5,name.group=c("belt","arm","dumbell", "foream","classe"))
plot(pca3,choix="ind",partial="all")
pca3 = MFA(myTraining, group=c(13,13,13,13,1),type=c(rep("s",1),rep("s",1),rep("s",1),rep("s",1),rep("n",1)), ncp=5,name.group=c("belt","arm","dumbell", "foream","classe"))
pca3 = MFA(myTraining, group=c(13,13,13,13,1),type=c(rep("s",1),rep("s",1),rep("s",1),rep("s",1),rep("n",1)), ncp=5,name.group=c("belt","arm","dumbell", "foream","classe"),num.group.sup = c(1,5))
pca3 = MFA(myTraining, group=c(13,13,13,13,1),type=c(rep("s",1),rep("s",1),rep("s",1),rep("s",1),rep("n",1)), ncp=5, name.group=c("belt","arm","dumbell", "foream","classe"),num.group.sup = c(1,5))
plot(pca3,choix="ind",partial="all")
trainingV3 <- myTraining
for(i in 1:length(myTraining)) {
if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .7) {
for(j in 1:length(trainingV3)) {
if( length( grep(names(myTraining[i]), names(trainingV3)[j]) ) == 1)  {
trainingV3 <- trainingV3[ , -j]
}
}
}
}
# Set back to the original variable name
myTraining <- trainingV3
rm(trainingV3)
trainCols <- colnames(myTraining)
testCols <- colnames(myTraining[, -53])  # remove the classe column
myTesting <- myTesting[trainCols]         # ensure column are same across train and test datasets
myTesting <- testing[testCols]
dim(myTesting)
set.seed(12345)
trainUrl <- "PML-Assignment.git/pml-training.csv"
testUrl <- "PML-Assignment.git/pml-testing.csv"
rmna.strings <- c("NA","#DIV/0!","")
training <- read.csv(trainUrl, na.strings=rmna.strings)
testing <- read.csv(testUrl, na.strings=rmna.strings)
inTrain <- createDataPartition(training$classe, p=0.6, list=FALSE)
pmlTraining <- training[inTrain, ]
pmlTesting <- training[-inTrain, ]
dim(pmlTraining)
dim(pmlTesting)
myTraining <- pmlTraining[ , 8:160]
myTesting <- pmlTesting[ , 8:160]
trainingV3 <- myTraining
for(i in 1:length(myTraining)) {
if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .7) {
for(j in 1:length(trainingV3)) {
if( length( grep(names(myTraining[i]), names(trainingV3)[j]) ) == 1)  {
trainingV3 <- trainingV3[ , -j]
}
}
}
}
# Set back to the original variable name
myTraining <- trainingV3
rm(trainingV3)
trainCols <- colnames(myTraining)
testCols <- colnames(myTraining[, -53])  # remove the classe column
myTesting <- myTesting[trainCols]         # ensure column are same across train and test datasets
myTesting <- testing[testCols]
dim(myTesting)
nzv <- nearZeroVar(pmlTraining, saveMetrics=TRUE)
myTraining <- pmlTraining[,nzv$nzv==FALSE]
myTesting <- pmlTesting[,nzv$nzv==FALSE]
set.seed(12345)
trainUrl <- "PML-Assignment.git/pml-training.csv"
testUrl <- "PML-Assignment.git/pml-testing.csv"
rmna.strings <- c("NA","#DIV/0!","")
training <- read.csv(trainUrl, na.strings=rmna.strings)
testing <- read.csv(testUrl, na.strings=rmna.strings)
inTrain <- createDataPartition(training$classe, p=0.6, list=FALSE)
pmlTraining <- training[inTrain, ]
pmlTesting <- training[-inTrain, ]
dim(pmlTraining)
dim(pmlTesting)
nzv <- nearZeroVar(pmlTraining, saveMetrics=TRUE)
myTraining <- pmlTraining[,nzv$nzv==FALSE]
myTesting <- pmlTesting[,nzv$nzv==FALSE]
myTraining <- pmlTraining[ , 8:160]
myTesting <- pmlTesting[ , 8:160]
trainingV3 <- myTraining
for(i in 1:length(myTraining)) {
if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .7) {
for(j in 1:length(trainingV3)) {
if( length( grep(names(myTraining[i]), names(trainingV3)[j]) ) == 1)  {
trainingV3 <- trainingV3[ , -j]
}
}
}
}
# Set back to the original variable name
myTraining <- trainingV3
rm(trainingV3)
trainCols <- colnames(myTraining)
testCols <- colnames(myTraining[, -53])  # remove the classe column
myTesting <- myTesting[trainCols]         # ensure column are same across train and test datasets
myTesting <- testing[testCols]
dim(myTesting)
pca3 = MFA(myTraining, group=c(3,35,29,35,27,1),type=c(rep("s",1),rep("s",1),rep("s",1),rep("s",1),rep("s",1),rep("n",1)), ncp=5,name.group=c("timestamp","belt","arm","dumbell", "foream","classe"),num.group.sup = c(1,5))
plot(pca3,choix="ind",partial="3")
pca3 = MFA(myTraining, group=c(13,13,13,13,1),type=c(rep("s",1),rep("s",1),rep("s",1),rep("s",1),rep("n",1)), ncp=5, name.group=c("belt","arm","dumbell", "foream","classe"),num.group.sup = c(1,5))
plot(pca3,choix="ind",partial="all")
pca3 = MFA(myTraining, group=c(13,13,13,13,1),type=c(rep("s",1),rep("s",1),rep("s",1),rep("s",1),rep("n",1)), ncp=5, name.group=c("belt","arm","dumbell","foream","classe"),num.group.sup = c(1,5))
summary(pca3)
myTraining <- pmlTraining[ , 7:160]
myTesting <- pmlTesting[ , 7:160]
trainingV3 <- myTraining
for(i in 1:length(myTraining)) {
if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .7) {
for(j in 1:length(trainingV3)) {
if( length( grep(names(myTraining[i]), names(trainingV3)[j]) ) == 1)  {
trainingV3 <- trainingV3[ , -j]
}
}
}
}
# Set back to the original variable name
myTraining <- trainingV3
rm(trainingV3)
trainCols <- colnames(myTraining)
testCols <- colnames(myTraining[, -53])  # remove the classe column
myTesting <- myTesting[trainCols]         # ensure column are same across train and test datasets
myTesting <- testing[testCols]
dim(myTesting)
trainCols <- colnames(myTraining)
testCols <- colnames(myTraining[, -54])  # remove the classe column
myTesting <- myTesting[trainCols]         # ensure column are same across train and test datasets
myTesting <- testing[testCols]
dim(myTesting)
correl = cor(train1[,c("yaw_belt","roll_belt","num_window","pitch_belt","magnet_dumbbell_z","magnet_dumbbell_y","pitch_forearm","accel_dumbbell_y","roll_arm","roll_forearm")])
diag(correl) <- 0
which(abs(correl)>0.75, arr.ind=TRUE)
correl = cor(pca3[,c("yaw_belt","roll_belt","num_window","pitch_belt","magnet_dumbbell_z","magnet_dumbbell_y","pitch_forearm","accel_dumbbell_y","roll_arm","roll_forearm")])
diag(correl) <- 0
which(abs(correl)>0.75, arr.ind=TRUE)
correl = cor(pca3[,c("roll_belt","pitch_belt","yaw_belt","total_accel_belt","gyros_belt_x","gyros_belt_y","gyros_belt_z","accel_belt_x","accel_belt_y","accel_belt_z")])
diag(correl) <- 0
which(abs(correl)>0.75, arr.ind=TRUE)
correl = cor(pca3[,c("roll_belt","pitch_belt","yaw_belt","total_accel_belt","gyros_belt_x","gyros_belt_y","gyros_belt_z","accel_belt_x","accel_belt_y","accel_belt_z")])
correl = cor(myTraining[,c("roll_belt","pitch_belt","yaw_belt","total_accel_belt","gyros_belt_x","gyros_belt_y","gyros_belt_z","accel_belt_x","accel_belt_y","accel_belt_z")])
diag(correl) <- 0
which(abs(correl)>0.75, arr.ind=TRUE)
which(abs(correl)>0.95, arr.ind=TRUE)
diag(correl) <- 0
which(abs(correl)>0.99, arr.ind=TRUE)
qplot(roll_belt, accel_belt_z, colour=classe, data=myTraining)
set.seed(12345)
fitModel <- randomForest(classe~., data=myTraining, importance=TRUE, ntree=100)
varImpPlot(fitModel)
summary(fitModel)
correl = cor(myTraining[,c("yaw_belt","roll_belt","num_window","pitch_belt","magnet_dumbbell_z","magnet_dumbbell_y","pitch_forearm","accel_dumbbell_y","roll_arm","roll_forearm")])
diag(correl) <- 0
which(abs(correl)>0.75, arr.ind=TRUE)
qplot(roll_belt, yaw_belt, colour=classe, data=myTraining)
cor(myTraining$roll_belt, myTraining$yaw_belt)
qplot(roll_belt, magnet_dumbbell_y, colour=classe, data=myTraining)
fitModel <- rpart(classe~., data=myTraining, method="class")
prp(fitModel)
setwd("~/GitHub")
set.seed(12345)
trainUrl <- "/PML-Assignment.git/pml-training.csv"
testUrl <- "/PML-Assignment.git/pml-testing.csv"
rmna.strings <- c("NA","#DIV/0!","")
training <- read.csv(trainUrl, na.strings=rmna.strings)
testing <- read.csv(testUrl, na.strings=rmna.strings)
setwd("C:\Users\Sree\Documents\GitHub\PML-Assignment.git")
setwd("C:\\Users\Sree\Documents\GitHub\PML-Assignment.git")
setwd("C://Users\Sree\Documents\GitHub\PML-Assignment.git")
setwd("C://Users/Sree/Documents/GitHub/PML-Assignment.git")
setwd("C://Users/Sree/Documents/GitHub")
```{r,echo=FALSE}
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
library(knitr)
library(FactoMineR)
library(randomForest)
setwd("C://Users/Sree/Documents/GitHub")
set.seed(12345)
trainUrl <- "PML-Assignment.git/pml-training.csv"
testUrl <- "PML-Assignment.git/pml-testing.csv"
rmna.strings <- c("NA","#DIV/0!","")
training <- read.csv(trainUrl, na.strings=rmna.strings)
testing <- read.csv(testUrl, na.strings=rmna.strings)
```{r}
inTrain <- createDataPartition(training$classe, p=0.6, list=FALSE)
pmlTraining <- training[inTrain, ]
pmlTesting <- training[-inTrain, ]
dim(pmlTraining)
dim(pmlTesting)
inTrain <- createDataPartition(training$classe, p=0.6, list=FALSE)
pmlTraining <- training[inTrain, ]
pmlTesting <- training[-inTrain, ]
dim(pmlTraining)
dim(pmlTesting)
inTrain <- createDataPartition(training$classe, p=0.6, list=FALSE)
pmlTraining <- training[inTrain, ]
pmlTesting <- training[-inTrain, ]
dim(pmlTraining)
dim(pmlTesting)
inTrain <- createDataPartition(training$classe, p=0.6, list=FALSE)
setwd("C:/Users/Sree/Documents/GitHub")
set.seed(12345)
rmna.strings <- c("NA","#DIV/0!","")
training <- read.csv(pml-training.csv, na.strings=rmna.strings)
testing <- read.csv(pml-training.csv, na.strings=rmna.strings)
setwd("C:/Users/Sree/Documents/GitHub/PML-Assignment.git")
set.seed(12345)
rmna.strings <- c("NA","#DIV/0!","")
training <- read.csv("pml-training.csv", na.strings=rmna.strings)
testing <- read.csv("pml-training.csv", na.strings=rmna.strings)
summary(pca1)
pca1 = MFA(myTraining, group=c(13,13,13,13,1),type=c(rep("s",1),rep("s",1),rep("s",1),rep("s",1),rep("n",1)), ncp=5, name.group=c("belt","arm","dumbell","forearm","classe"),num.group.sup = c(1,5))
summary(pca1)
trainCols <- colnames(myTraining)
testCols <- colnames(myTraining[, -54])  # remove the classe column
myTesting <- myTesting[trainCols]         # ensure column are same across train and test datasets
myTesting <- testing[testCols]
dim(myTesting)
source('~/.active-rstudio-document', echo=TRUE)
head(myTraining)
colnames(myTraining)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
```{r}
set.seed(12345)
modelFit <- randomForest(classe~., data=myTraining, importance=TRUE, ntree=100)
varImpPlot(modelFit)
```
set.seed(12345)
modelFit <- randomForest(classe~., data=myTraining, importance=TRUE, ntree=100)
varImpPlot(modelFit)
MFA(base = myTraining, group = c(1, 13, 13, 13, 13, 1), type = c(rep("s",1), rep("s", 1), rep("s", 1), rep("s", 1), rep("s", 1), rep("n",  1)), ncp = 5, name.group = c("num_win", "belt", "arm", "dumbell","forearm", "classe"), num.group.sup = c(1, 5))
MFA(base = myTraining, group = c(1, 13, 13, 13, 13, 1), type = c(rep("s",1), rep("s", 1), rep("s", 1), rep("s", 1), rep("s", 1), rep("n",  1)), ncp = 1, name.group = c("num_win", "belt", "arm", "dumbell","forearm", "classe"), num.group.sup = c(1, 1))
MFA(base = myTraining, group = c(1, 13, 13, 13, 13, 1), type = c(rep("s",1), rep("s", 1), rep("s", 1), rep("s", 1), rep("s", 1), rep("n",  1)), ncp = 2, name.group = c("num_win", "belt", "arm", "dumbell","forearm", "classe"), num.group.sup = c(1, 2))
mfactorAnalysis <- MFA(base = myTraining, group = c(1, 13, 13, 13, 13, 1), type = c(rep("s",1), rep("s", 1), rep("s", 1), rep("s", 1), rep("s", 1), rep("n",  1)), ncp = 2, name.group = c("num_win", "belt", "arm", "dumbell","forearm", "classe"), num.group.sup = c(1, 2))
plot(mfactorAnalysis,choix="ind",partial="all")
mfactorAnalysis$global.pca
mfactorAnalysis$global.pca
mfactorAnalysis$quanti.sup$cor"
mfactorAnalysis$quanti.sup$cor
mfactorAnalysis$quanti.sup$cor
mfactorAnalysis$call
mfactorAnalysis$global.pca
mfactorAnalysis$quanti.sup$coord
set.seed(12345)
modelFit <- randomForest(classe~., data=myTraining, importance=TRUE, ntree=100)
varImpPlot(modelFit)
```{r}
modelFit <- rpart(classe~., data=myTraining, method="class")
prp(modelFit)
```
set.seed(12345)
fitModel <- train(classe~roll_belt+num_window+pitch_belt+magnet_dumbbell_y+magnet_dumbbell_z+pitch_forearm+accel_dumbbell_y+roll_arm+roll_forearm,
data=myTraining,
method="rf",
trControl=trainControl(method="cv",number=2),
prox=TRUE,
verbose=TRUE,
allowParallel=TRUE)
saveRDS(fitModel, "modelRF.Rds")
fitModel <- readRDS("modelRF.Rds")
predictions <- predict(fitModel, newdata=myTesting)
confusionMat <- confusionMatrix(predictions, myTesting$classe)
confusionMat
fitModel <- train(classe~roll_belt+num_window+pitch_belt+magnet_dumbbell_y+magnet_dumbbell_z+pitch_forearm+accel_dumbbell_y+roll_arm+roll_forearm,
data=myTraining,
method="rf",
trControl=trainControl(method="cv",number=2),
prox=TRUE,
verbose=TRUE,
allowParallel=TRUE)
set.seed(12345)
fitModel <- train(classe~roll_belt+num_window+pitch_belt+magnet_dumbbell_y+magnet_dumbbell_z+pitch_forearm+accel_dumbbell_y+roll_arm+roll_forearm,
data=myTraining,
method="rf",
trControl=trainControl(method="cv",number=2),
prox=TRUE,
verbose=TRUE,
allowParallel=TRUE)
saveRDS(fitModel, "modelRF.Rds")
fitModel <- readRDS("modelRF.Rds")
set.seed(12345)
fitModel <- train(classe~roll_belt+num_window+pitch_belt+magnet_dumbbell_y+magnet_dumbbell_z+pitch_forearm+accel_dumbbell_y+roll_arm+roll_forearm,
data=myTraining,
method="rf",
trControl=trainControl(method="cv",number=2),
prox=TRUE,
verbose=TRUE,
allowParallel=TRUE)
predictions <- predict(fitModel, newdata=myTesting)
confusionMat <- confusionMatrix(predictions, myTesting$classe)
confusionMat
predictions <- predict(fitModel, newdata=myTesting)
confusionMat <- confusionMatrix(predictions, myTesting$classe)
confusionMat <- confusionMatrix(predictions, myTesting$classe)
set.seed(12345)
fitModel <- train(classe~roll_belt+num_window+pitch_belt+magnet_dumbbell_y+magnet_dumbbell_z+pitch_forearm+accel_dumbbell_y+roll_arm+roll_forearm,
data=myTraining,
method="rf",
trControl=trainControl(method="cv",number=2),
prox=TRUE,
verbose=TRUE,
allowParallel=TRUE)
saveRDS(fitModel, "modelRF.Rds")
fitModel <- readRDS("modelRF.Rds")
predictions <- predict(fitModel, newdata=myTesting)
confusionMat <- confusionMatrix(predictions, myTesting$classe)
confusionMat
predictions <- predict(fitModel, newdata=myTesting)
myTesting$classe
confusionMat <- confusionMatrix(predictions, myTraining$classe)
##myTesting <- testing[testCols]
source('~/.active-rstudio-document', echo=TRUE)
confusionMat <- confusionMatrix(predictions, fitModel$classe)
confusionMat <- confusionMatrix(predictions, newdata$classe)
predictions <- predict(fitModel, newdata=myTesting)
confusionMat <- confusionMatrix(predictions, predictions$classe)
confusionMat <- confusionMatrix(predictions, myTesting$classe)
confusionMat <- confusionMatrix(predictions, myTesting$classe)
confusionMat
missClass = function(values, predicted) {
sum(predicted != values) / length(values)
}
OOS_errRate = missClass(myTesting$classe, predictions)
OOS_errRate
predictions <- predict(fitModel, newdata=testing)
testing$classe <- predictions
submit <- data.frame(problem_id = testing$problem_id, classe = predictions)
write.csv(submit, file = "coursera-submission.csv", row.names = FALSE)
predictions <- predict(fitModel, newdata=myTesting)
myTesting$classe <- predictions
submit <- data.frame(problem_id = testing$problem_id, classe = predictions)
write.csv(submit, file = "coursera-submission.csv", row.names = FALSE)
submit <- data.frame(problem_id = myTesting$problem_id, classe = predictions)
write.csv(submit, file = "coursera-submission.csv", row.names = FALSE)
predictions <- predict(fitModel, newdata=myTesting)
myTesting$classe <- predictions
submit <- data.frame(problem_id = myTesting$problem_id, classe = predictions)
write.csv(submit, file = "coursera-submission.csv", row.names = FALSE)
submit <- data.frame(problem_id = myTesting$problem_id, classe = predictions)
confusionMat <- confusionMatrix(predictions, myTesting$classe)
confusionMat
missClass = function(values, predicted) {
sum(predicted != values) / length(values)
}
OOS_errRate = missClass(myTesting$classe, predictions)
OOS_errRate
predictions <- predict(fitModel, newdata=testing)
testing$classe <- predictions
predictions <- predict(fitModel, newdata=myTesting)
testing$classe <- predictions
missClass = function(values, predicted) {
sum(predicted != values) / length(values)
}
OOS_errRate = missClass(myTesting$classe, predictions)
OOS_errRate
predictions <- predict(fitModel, newdata=myTesting)
myTesting$classe <- predictions
submit <- data.frame(problem_id = myTesting$problem_id, classe = predictions)
write.csv(submit, file = "coursera-submission.csv", row.names = FALSE)
submit <- data.frame(problem_id = testing$problem_id, classe = predictions)
write.csv(submit, file = "coursera-submission.csv", row.names = FALSE)
```
submit <- data.frame(problem_id = myTesting$problem_id, classe = predictions)
write.csv(submit, file = "coursera-submission.csv", row.names = FALSE)
myTesting$classe
submit <- data.frame(problem_id = myTesting$problem_id, classe = predictions)
write.csv(submit, file = "coursera-submission.csv", row.names = FALSE)
predictions <- predict(fitModel, newdata=myTesting)
testing$classe <- predictions
predictions <- predict(fitModel, newdata=myTesting)
testing$classe <- predictions
missClass = function(values, predicted) {
sum(predicted != values) / length(values)
}
OOS_errRate = missClass(myTesting$classe, predictions)
OOS_errRate
predictions
predictions <- predict(fitModel, newdata=myTesting)
testing$classe <- predictions
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
library(knitr)
library(FactoMineR)
library(randomForest)
setwd("C:/Users/Sree/Documents/GitHub/PML-Assignment.git")
set.seed(12345)
rmna.strings <- c("NA","#DIV/0!","")
training <- read.csv("pml-training.csv", na.strings=rmna.strings)
testing <- read.csv("pml-training.csv", na.strings=rmna.strings)
training <- read.csv("pml-training.csv", na.strings = c("NA", "#DIV/0!", ""))
testing  <- read.csv("pml-testing.csv",  na.strings = c("NA", "#DIV/0!", ""))
str(training, list.len=15)
table(training$classe)
prop.table(table(training$user_name, training$classe), 1)
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
library(knitr)
library(FactoMineR)
library(randomForest)
setwd("C:/Users/Sree/Documents/GitHub/PML-Assignment.git")
set.seed(12345)
rmna.strings <- c("NA","#DIV/0!","")
training <- read.csv("pml-training.csv", na.strings = c("NA", "#DIV/0!", ""))
testing  <- read.csv("pml-testing.csv",  na.strings = c("NA", "#DIV/0!", ""))
str(training, list.len=15)
table(training$classe)
prop.table(table(training$user_name, training$classe), 1)
prop.table(table(training$classe))
training <- training[, 7:160]
testing  <- testing[, 7:160]
is_data  <- apply(!is.na(training), 2, sum) > 19621  # which is the number of observations
training <- training[, is_data]
testing  <- testing[, is_data]
set.seed(3141592)
inTrain <- createDataPartition(y=training$classe, p=0.60, list=FALSE)
train1  <- training[inTrain,]
train2  <- training[-inTrain,]
dim(train1)
dim(train2)
nzv_cols <- nearZeroVar(train1)
if(length(nzv_cols) > 0) {
train1 <- train1[, -nzv_cols]
train2 <- train2[, -nzv_cols]
}
dim(train1)
dim(train2)
set.seed(3141592)
fitModel <- randomForest(classe~., data=train1, importance=TRUE, ntree=100)
varImpPlot(fitModel)
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
library(knitr)
library(FactoMineR)
library(randomForest)
setwd("C:/Users/Sree/Documents/GitHub/PML-Assignment.git")
set.seed(12345)
rmna.strings <- c("NA","#DIV/0!","")
training <- read.csv("pml-training.csv", na.strings = c("NA", "#DIV/0!", ""))
testing  <- read.csv("pml-testing.csv",  na.strings = c("NA", "#DIV/0!", ""))
str(training, list.len=15)
table(training$classe)
prop.table(table(training$user_name, training$classe), 1)
prop.table(table(training$classe))
training <- training[, 7:160]
testing  <- testing[, 7:160]
is_data  <- apply(!is.na(training), 2, sum) > 19621  # which is the number of observations
training <- training[, is_data]
testing  <- testing[, is_data]
set.seed(12345)
inTrain <- createDataPartition(y=training$classe, p=0.60, list=FALSE)
train1  <- training[inTrain,]
train2  <- training[-inTrain,]
dim(train1)
dim(train2)
nzv_cols <- nearZeroVar(train1)
if(length(nzv_cols) > 0) {
train1 <- train1[, -nzv_cols]
train2 <- train2[, -nzv_cols]
}
dim(train1)
dim(train2)
set.seed(12345)
fitModel <- randomForest(classe~., data=train1, importance=TRUE, ntree=100)
varImpPlot(fitModel)
cor(train1$roll_belt, train1$yaw_belt)
set.seed(12345)
fitModel <- randomForest(classe~., data=train1, importance=TRUE, ntree=100)
varImpPlot(fitModel)
cor(train1$roll_belt, train1$yaw_belt)
qplot(roll_belt, magnet_dumbbell_y, colour=classe, data=train1)
fitModel <- rpart(classe~., data=train1, method="class")
prp(fitModel)
set.seed(12345)
fitModel <- train(classe~roll_belt+num_window+pitch_belt+magnet_dumbbell_y+magnet_dumbbell_z+pitch_forearm+accel_dumbbell_y+roll_arm+roll_forearm,
data=train1,
method="rf",
trControl=trainControl(method="cv",number=2),
prox=TRUE,
verbose=TRUE,
allowParallel=TRUE)
saveRDS(fitModel, "modelRF.Rds")
fitModel <- readRDS("modelRF.Rds")
predictions <- predict(fitModel, newdata=train2)
confusionMat <- confusionMatrix(predictions, train2$classe)
confusionMat
missClass = function(values, predicted) {
sum(predicted != values) / length(values)
}
OOS_errRate = missClass(train2$classe, predictions)
OOS_errRate
predictions <- predict(fitModel, newdata=testing)
testing$classe <- predictions
submit <- data.frame(problem_id = testing$problem_id, classe = predictions)
write.csv(submit, file = "coursera-submission.csv", row.names = FALSE)
